{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a detailed example of model training for `mobilenet_v2`, `test_data` of ants and bees and default imbalanced tool (actually, here is a content of `model_trainin.py`). All training constants are placed into `config.py`. \n",
    "\n",
    "In more comfortable and faster way the training can also be launched by running `model_trainin.py` with desired configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(os.path.join('..', 'src'))\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pandas.io.json._normalize import nested_to_record\n",
    "\n",
    "from utils import nn_utils, image_utils, augmentation\n",
    "from utils.model_training_utils import get_computing_device, load_pytorch_model, get_optimizer, \\\n",
    "                                       PytorchDataset, SaveBestModelCallback, model_train\n",
    "\n",
    "import resnet_selector\n",
    "import mobilenet_selector\n",
    "\n",
    "import neptune_logger\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict for imbalanced params setting\n",
    "imbalanced_dict = {'train_sampler': {'default': False,\n",
    "                                     'weighted_loss': False,\n",
    "                                     'train_sampler': True\n",
    "                                     },\n",
    "                   'weighted_loss': {'default': False,\n",
    "                                     'weighted_loss': True,\n",
    "                                     'train_sampler': False\n",
    "                                     },\n",
    "                   'tag': {'default': 'default',\n",
    "                           'weighted_loss': 'weighted_loss',\n",
    "                           'train_sampler': 'custom_batch_sampler'\n",
    "                           }\n",
    "                   }\n",
    "imbalanced_tool = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'model': {'model_name': 'mobilenet_v2',           \n",
    "                        'optimizer': config.MODEL_OPTIMIZER,\n",
    "                        'pretrained': config.PRETRAINED,\n",
    "                        'freeze_conv': config.FREEZE_CONV,\n",
    "                        'epochs': config.EPOCHS,\n",
    "                        'batch_size': config.BATCH_SIZE,\n",
    "                        },\n",
    "\n",
    "              'data': {'root_dir': os.getcwd().replace('src', 'datasets'),\n",
    "                       'dataset_name': 'test_data',\n",
    "                       'resize_img': config.RESIZE_IMG,\n",
    "                       'num_workers': config.NUM_WORKERS,\n",
    "                       'pytorch_aug': config.PYTORCH_AUG,\n",
    "                       'save_aspect_ratio': config.SAVE_ASPECT_RATIO,\n",
    "                       'imgaug_aug': config.IMGAUG_AUG,\n",
    "                       'img_normalize': config.IMG_NORMALIZE,\n",
    "                       },\n",
    "\n",
    "              'imbalanced_tools': {'train_sampler': imbalanced_dict['train_sampler'][imbalanced_tool],\n",
    "                                   'weighted_loss': imbalanced_dict['weighted_loss'][imbalanced_tool],\n",
    "                                   }\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Workers: 8\n"
     ]
    }
   ],
   "source": [
    "NEPTUNE_EXPERIMENT_TAG_LIST = [CONFIG['data']['dataset_name'],\n",
    "                               CONFIG['model']['model_name'],\n",
    "                               'imbalanced_tools',\n",
    "                               imbalanced_dict['tag'][imbalanced_tool],\n",
    "                               ]\n",
    "\n",
    "DEVICE = get_computing_device()\n",
    "CONFIG.update({'seed': config.SEED})\n",
    "np.random.seed(config.SEED)\n",
    "torch.manual_seed(config.SEED)\n",
    "\n",
    "FULL_DATASET_DIR = os.path.join(CONFIG['data']['root_dir'],\n",
    "                                    CONFIG['data']['dataset_name'])\n",
    "CLASS_DICT = image_utils.make_class_dict(os.path.join(FULL_DATASET_DIR, 'df_img_meta.csv'))\n",
    "\n",
    "print('Workers:', CONFIG['data']['num_workers'])\n",
    "if CONFIG['data']['num_workers'] > 0:\n",
    "    cv2.setNumThreads(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting image transformations\n",
    "_pytorch_aug = CONFIG['data']['pytorch_aug']\n",
    "_img_normalize = CONFIG['data']['img_normalize']\n",
    "_save_aspect_ratio = CONFIG['data']['save_aspect_ratio']\n",
    "\n",
    "default_transforms_list = [augmentation.ImgAugTransform(with_aug=False),\n",
    "                           image_utils.CustomResize((CONFIG['data']['resize_img'],\n",
    "                                         CONFIG['data']['resize_img']),\n",
    "                                        _save_aspect_ratio\n",
    "                                        ),\n",
    "                           torchvision.transforms.ToTensor()\n",
    "                           ]\n",
    "\n",
    "if _pytorch_aug:\n",
    "    # Pytorch default & augmentation transform\n",
    "    transform_list = [augmentation.ImgAugTransform(with_aug=CONFIG['data']['imgaug_aug']),\n",
    "                      image_utils.CustomResize((CONFIG['data']['resize_img'],\n",
    "                                    CONFIG['data']['resize_img']),\n",
    "                                   _save_aspect_ratio\n",
    "                                   ),\n",
    "                      torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "                      torchvision.transforms.RandomHorizontalFlip(),\n",
    "                      torchvision.transforms.RandomRotation(20, resample=Image.BILINEAR),\n",
    "                      torchvision.transforms.ToTensor()\n",
    "                      ]\n",
    "else:\n",
    "    transform_list = [augmentation.ImgAugTransform(with_aug=CONFIG['data']['imgaug_aug']),\n",
    "                      image_utils.CustomResize((CONFIG['data']['resize_img'],\n",
    "                                    CONFIG['data']['resize_img']),\n",
    "                                   _save_aspect_ratio\n",
    "                                   ),\n",
    "                      torchvision.transforms.ToTensor()\n",
    "                      ]\n",
    "\n",
    "if _img_normalize:\n",
    "    # Parameters were taken from Pytorch example for Imagenet\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py#L197-L198\n",
    "    transform_list.append(torchvision.transforms.Normalize(mean=config.IMG_NORMALIZE_MEAN,\n",
    "                                                           std=config.IMG_NORMALIZE_STD)\n",
    "                          )\n",
    "    default_transforms_list.append(torchvision.transforms.Normalize(mean=config.IMG_NORMALIZE_MEAN,\n",
    "                                                                    std=config.IMG_NORMALIZE_STD)\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose(transform_list)\n",
    "val_trainsforms = torchvision.transforms.Compose(default_transforms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dictionaries for training, validation and testing\n",
    "TRAIN_DATASET_KWARGS = {'class_dict': CLASS_DICT,\n",
    "                        'dataset_rootdir': FULL_DATASET_DIR,\n",
    "                        'val_size': config.TESTVAL_SIZE,\n",
    "                        'test_size': config.TEST_SIZE_FROM_TESTVAL,   # Доля от val_size\n",
    "                        'seed': config.SEED,\n",
    "                        'torch_transform': train_transforms,\n",
    "                        }\n",
    "\n",
    "TESTVAL_DATASET_KWARGS = {'class_dict': CLASS_DICT,\n",
    "                          'dataset_rootdir': FULL_DATASET_DIR,\n",
    "                          'val_size': config.TESTVAL_SIZE,\n",
    "                          'test_size': config.TEST_SIZE_FROM_TESTVAL,  # Доля от val_size\n",
    "                          'seed': config.SEED,\n",
    "                          'torch_transform': val_trainsforms,\n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Pytorch TRAIN dataset kwargs:===========\n",
      "class_dict: {'ants': 0, 'bees': 1}\n",
      "dataset_rootdir: /home/alexander/Documents/py_projects/github/insects-recognition/datasets/test_data\n",
      "val_size: 0.3\n",
      "test_size: 0.5\n",
      "seed: 42\n",
      "torch_transform: Compose(\n",
      "    <utils.augmentation.ImgAugTransform object at 0x7f3bd7df5cd0>\n",
      "    <utils.image_utils.CustomResize object at 0x7f3bd7df5e90>\n",
      "    ColorJitter(brightness=None, contrast=None, saturation=[0.95, 1.05], hue=[-0.05, 0.05])\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomRotation(degrees=(-20, 20), resample=2, expand=False)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "\n",
      "Unique classes in /home/alexander/Documents/py_projects/github/insects-recognition/datasets/test_data:\n",
      "['bees', 'ants']\n",
      "Mapping class dictionary: {'ants': 0, 'bees': 1}\n",
      "Number of observations for TRAIN: 170\n",
      "\n",
      "TRAIN classes:  2\n",
      "0    86\n",
      "1    84\n",
      "Name: class, dtype: int64\n",
      "VAL classes:  2\n",
      "1    18\n",
      "0    18\n",
      "Name: class, dtype: int64\n",
      "TEST classes:  2\n",
      "1    19\n",
      "0    19\n",
      "Name: class, dtype: int64\n",
      "===========Pytorch VAL dataset kwargs:============\n",
      "class_dict: {'ants': 0, 'bees': 1}\n",
      "dataset_rootdir: /home/alexander/Documents/py_projects/github/insects-recognition/datasets/test_data\n",
      "val_size: 0.3\n",
      "test_size: 0.5\n",
      "seed: 42\n",
      "torch_transform: Compose(\n",
      "    <utils.augmentation.ImgAugTransform object at 0x7f3bd7df5c90>\n",
      "    <utils.image_utils.CustomResize object at 0x7f3bd82e6290>\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "\n",
      "Unique classes in /home/alexander/Documents/py_projects/github/insects-recognition/datasets/test_data:\n",
      "['bees', 'ants']\n",
      "Mapping class dictionary: {'ants': 0, 'bees': 1}\n",
      "Number of observations for VAL: 36\n",
      "\n",
      "TRAIN classes:  2\n",
      "0    86\n",
      "1    84\n",
      "Name: class, dtype: int64\n",
      "VAL classes:  2\n",
      "1    18\n",
      "0    18\n",
      "Name: class, dtype: int64\n",
      "TEST classes:  2\n",
      "1    19\n",
      "0    19\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_dataset = PytorchDataset('train', TRAIN_DATASET_KWARGS)\n",
    "val_dataset = PytorchDataset('val', TESTVAL_DATASET_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What sampler for batching to choose\n",
    "if CONFIG['imbalanced_tools']['train_sampler']:\n",
    "\n",
    "    _train_shuffle = False\n",
    "    _train_sampler = nn_utils.ImbalancedDatasetSampler(dataset=train_dataset,\n",
    "                                                       class_dict=CLASS_DICT,\n",
    "                                                       random_state=config.SEED)\n",
    "else:\n",
    "    _train_shuffle = True\n",
    "    _train_sampler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_dataset,\n",
    "                               batch_size=CONFIG['model']['batch_size'],\n",
    "                               shuffle=_train_shuffle, \n",
    "                               sampler=_train_sampler,\n",
    "                               num_workers=CONFIG['data']['num_workers'])\n",
    "val_data_loader = DataLoader(val_dataset, \n",
    "                             batch_size=CONFIG['model']['batch_size'],\n",
    "                             shuffle=True, \n",
    "                             num_workers=CONFIG['data']['num_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers and their parameters\n",
    "# https://pytorch.org/docs/stable/optim.html\n",
    "OPTIM_KWARGS = {'optimizer': {'adadelta': {'lr': 1.0, 'rho': 0.9, 'eps': 1e-06, 'weight_decay': 0},\n",
    "\n",
    "                              'adagrad': {'lr': 0.01, 'lr_decay': 0, 'weight_decay': 0,\n",
    "                                          'initial_accumulator_value': 0, 'eps': 1e-10},\n",
    "\n",
    "                              'adam': {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08,\n",
    "                                       'weight_decay': 0, 'amsgrad': False},\n",
    "\n",
    "                              'adamw': {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08,\n",
    "\n",
    "                                        'weight_decay': 0.01, 'amsgrad': False},\n",
    "\n",
    "                              'adamax': {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08,\n",
    "                                         'weight_decay': 0},\n",
    "\n",
    "                              'rms_prop': {'lr': 0.01, 'alpha': 0.99, 'eps': 1e-08, 'weight_decay': 0,\n",
    "                                           'momentum': 0, 'centered': False}\n",
    "                              },\n",
    "\n",
    "                'lr_scheduler': {'mode': 'min', 'factor': 0.95, 'patience': 10, 'verbose': False,\n",
    "                                 'threshold': 0.0001, 'threshold_mode': 'rel', 'cooldown': 0, 'min_lr': 1e-9,\n",
    "                                 'eps': 1e-08}\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: mobilenet_v2\n"
     ]
    }
   ],
   "source": [
    "# Select and configure model to be trained\n",
    "# Number of classes\n",
    "n_classes = len(TRAIN_DATASET_KWARGS['class_dict'].keys())\n",
    "\n",
    "if 'mobilenet' in CONFIG['model']['model_name']:\n",
    "    nnet = mobilenet_selector.get_mobilenet(version=CONFIG['model']['model_name'],\n",
    "                                            class_number=n_classes,\n",
    "                                            pretrained=CONFIG['model']['pretrained'],\n",
    "                                            freeze_conv=CONFIG['model']['freeze_conv'])\n",
    "else:\n",
    "    nnet = resnet_selector.get_resnet(version=CONFIG['model']['model_name'],\n",
    "                                      class_number=n_classes,\n",
    "                                      pretrained=CONFIG['model']['pretrained'],\n",
    "                                      freeze_conv=CONFIG['model']['freeze_conv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to use weighted loss or not\n",
    "if CONFIG['imbalanced_tools']['weighted_loss']:\n",
    "    _label_to_count = train_dataset.df_metadata['class'].value_counts().to_dict()\n",
    "    _unnorm_weights = {k: 1 / v for k, v in _label_to_count.items()}\n",
    "    _normed_weights = {k: v / sum(_unnorm_weights.values()) for k, v in _unnorm_weights.items()}\n",
    "\n",
    "    _loss_weight = [v for k, v in sorted(_normed_weights.items(), key=lambda x: x[0])]\n",
    "    _loss_weight = torch.FloatTensor(_loss_weight).to(DEVICE)\n",
    "\n",
    "else:\n",
    "    _loss_weight = None\n",
    "\n",
    "# Set training keyword argumetns\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=_loss_weight)\n",
    "optimizer = get_optimizer(CONFIG['model']['optimizer'],\n",
    "                          nnet,\n",
    "                          OPTIM_KWARGS['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset img hashes to dataset hash. Universal for every machine.\n",
    "train_data_hash = hashlib.sha1(\n",
    "    '_'.join(sorted(train_dataset.df_metadata['sha1'].values.tolist())).encode()).hexdigest()\n",
    "\n",
    "training_kwargs = {'device': DEVICE,\n",
    "\n",
    "                   'criterion': criterion,\n",
    "                   'optimizer': optimizer,\n",
    "                   'lr_scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                                              **OPTIM_KWARGS['lr_scheduler']),\n",
    "\n",
    "                   'data_loaders': {'train_loader': train_data_loader,\n",
    "                                    'val_loader': val_data_loader},\n",
    "                   'total_epochs': 5, #CONFIG['model']['epochs'], \n",
    "                   # Here we set 5 epochs to look at the training process\n",
    "                   'batch_size': CONFIG['model']['batch_size'],\n",
    "                   'target_names': list(TRAIN_DATASET_KWARGS['class_dict'].keys()),\n",
    "\n",
    "                   'model_name': f\"\"\"{CONFIG['model']['model_name']}_{train_data_hash}\"\"\",\n",
    "                   'class_dict': CLASS_DICT,\n",
    "                   'save_path': os.path.join(os.getcwd(), 'weights'),\n",
    "                   'general_config': CONFIG\n",
    "                   }\n",
    "\n",
    "weights_folder = os.path.join(os.getcwd(), 'weights',\n",
    "                                  f\"\"\"pytorch_{CONFIG['model']['model_name']}_{train_data_hash}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neptune logger is OFF.\n"
     ]
    }
   ],
   "source": [
    "if config.USE_NEPTUNE:\n",
    "    print('Neptune logger is ON.')\n",
    "    # Сбор параметров для логгирования\n",
    "    TOTAL_PARAMS = {'config': CONFIG,\n",
    "                    'training_kwargs': training_kwargs,\n",
    "                    'train_dataset_kwargs': TRAIN_DATASET_KWARGS,\n",
    "                    'testval_dataset_kwargs': TESTVAL_DATASET_KWARGS,\n",
    "                    'weights_folder': weights_folder,\n",
    "                    'training_data_sha1': train_data_hash,\n",
    "                    }\n",
    "    neptune_kwargs = {'params': nested_to_record(TOTAL_PARAMS, sep='_'),\n",
    "                      'artifact_path': os.path.join(os.getcwd().replace('src', 'log_artifacts'), 'artifacts'),\n",
    "                      'image_path': os.path.join(os.getcwd().replace('src', 'log_artifacts'), 'images'),\n",
    "                      'tag_list': NEPTUNE_EXPERIMENT_TAG_LIST,\n",
    "                      'training_data_sha1': train_data_hash\n",
    "                      }\n",
    "    neptune_class = neptune_logger.NeptuneLogger(neptune_kwargs)\n",
    "else:\n",
    "    print('Neptune logger is OFF.')\n",
    "    neptune_class = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.59it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.99it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: inf -> 0.9481952786445618. Model was saved.\n",
      "[2.298963 sec.][Epoch 1] train_loss: 5.408033311367035, val_loss: 0.9481952786445618, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.85      0.94      0.89        18\n",
      "        bees       0.94      0.83      0.88        18\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.89      0.89      0.89        36\n",
      "weighted avg       0.89      0.89      0.89        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.32it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.176601 sec.][Epoch 2] train_loss: 4.735930815339088, val_loss: 3.564190149307251, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.74      0.94      0.83        18\n",
      "        bees       0.92      0.67      0.77        18\n",
      "\n",
      "    accuracy                           0.81        36\n",
      "   macro avg       0.83      0.81      0.80        36\n",
      "weighted avg       0.83      0.81      0.80        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  6.34it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.22it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.045006 sec.][Epoch 3] train_loss: 4.486488088965416, val_loss: 3.0880789756774902, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.85      0.61      0.71        18\n",
      "        bees       0.70      0.89      0.78        18\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.77      0.75      0.75        36\n",
      "weighted avg       0.77      0.75      0.75        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.75it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.30it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.219736 sec.][Epoch 4] train_loss: 2.99559935182333, val_loss: 4.566686153411865, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.88      0.83      0.86        18\n",
      "        bees       0.84      0.89      0.86        18\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.86      0.86      0.86        36\n",
      "weighted avg       0.86      0.86      0.86        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  5.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.399186 sec.][Epoch 5] train_loss: 3.0173875987529755, val_loss: 1.9760305881500244, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.85      0.94      0.89        18\n",
      "        bees       0.94      0.83      0.88        18\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.89      0.89      0.89        36\n",
      "weighted avg       0.89      0.89      0.89        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model_train(nnet, training_kwargs, neptune_class=neptune_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
