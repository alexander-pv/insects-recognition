{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a detailed example of model training for `mobilenet_v2`, `test_data` of ants and bees and default imbalanced tool (actually, here is a content of `model_trainin.py`). All training constants are placed into `config.py`. \n",
    "\n",
    "In more comfortable and faster way the training can also be launched by running `model_trainin.py` with desired configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(os.path.join('..', 'src'))\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pandas.io.json._normalize import nested_to_record\n",
    "\n",
    "from utils import nn_utils, image_utils, augmentation\n",
    "from utils.model_training_utils import get_computing_device, load_pytorch_model, get_optimizer, \\\n",
    "                                       PytorchDataset, SaveBestModelCallback, model_train\n",
    "\n",
    "import resnet_selector\n",
    "import mobilenet_selector\n",
    "\n",
    "import neptune_logger\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict for imbalanced params setting\n",
    "imbalanced_dict = {'train_sampler': {'default': False,\n",
    "                                     'weighted_loss': False,\n",
    "                                     'train_sampler': True\n",
    "                                     },\n",
    "                   'weighted_loss': {'default': False,\n",
    "                                     'weighted_loss': True,\n",
    "                                     'train_sampler': False\n",
    "                                     },\n",
    "                   'tag': {'default': 'default',\n",
    "                           'weighted_loss': 'weighted_loss',\n",
    "                           'train_sampler': 'custom_batch_sampler'\n",
    "                           }\n",
    "                   }\n",
    "imbalanced_tool = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'model': {'model_name': 'mobilenet_v2',           \n",
    "                        'optimizer': config.MODEL_OPTIMIZER,\n",
    "                        'pretrained': config.PRETRAINED,\n",
    "                        'freeze_conv': config.FREEZE_CONV,\n",
    "                        'epochs': config.EPOCHS,\n",
    "                        'batch_size': config.BATCH_SIZE,\n",
    "                        },\n",
    "\n",
    "              'data': {'root_dir': os.getcwd().replace('src', 'datasets'),\n",
    "                       'dataset_name': 'test_data',\n",
    "                       'resize_img': config.RESIZE_IMG,\n",
    "                       'num_workers': config.NUM_WORKERS,\n",
    "                       'pytorch_aug': config.PYTORCH_AUG,\n",
    "                       'save_aspect_ratio': config.SAVE_ASPECT_RATIO,\n",
    "                       'imgaug_aug': config.IMGAUG_AUG,\n",
    "                       'img_normalize': config.IMG_NORMALIZE,\n",
    "                       },\n",
    "\n",
    "              'imbalanced_tools': {'train_sampler': imbalanced_dict['train_sampler'][imbalanced_tool],\n",
    "                                   'weighted_loss': imbalanced_dict['weighted_loss'][imbalanced_tool],\n",
    "                                   }\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Workers: 8\n"
     ]
    }
   ],
   "source": [
    "NEPTUNE_EXPERIMENT_TAG_LIST = [CONFIG['data']['dataset_name'],\n",
    "                               CONFIG['model']['model_name'],\n",
    "                               'imbalanced_tools',\n",
    "                               imbalanced_dict['tag'][imbalanced_tool],\n",
    "                               ]\n",
    "\n",
    "DEVICE = get_computing_device()\n",
    "CONFIG.update({'seed': config.SEED})\n",
    "np.random.seed(config.SEED)\n",
    "torch.manual_seed(config.SEED)\n",
    "\n",
    "FULL_DATASET_DIR = os.path.join(CONFIG['data']['root_dir'],\n",
    "                                    CONFIG['data']['dataset_name'])\n",
    "CLASS_DICT = image_utils.make_class_dict(os.path.join(FULL_DATASET_DIR, 'df_img_meta.csv'))\n",
    "\n",
    "print('Workers:', CONFIG['data']['num_workers'])\n",
    "if CONFIG['data']['num_workers'] > 0:\n",
    "    cv2.setNumThreads(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting image transformations\n",
    "_pytorch_aug = CONFIG['data']['pytorch_aug']\n",
    "_img_normalize = CONFIG['data']['img_normalize']\n",
    "_save_aspect_ratio = CONFIG['data']['save_aspect_ratio']\n",
    "\n",
    "default_transforms_list = [augmentation.ImgAugTransform(with_aug=False),\n",
    "                           image_utils.CustomResize((CONFIG['data']['resize_img'],\n",
    "                                         CONFIG['data']['resize_img']),\n",
    "                                        _save_aspect_ratio\n",
    "                                        ),\n",
    "                           torchvision.transforms.ToTensor()\n",
    "                           ]\n",
    "\n",
    "if _pytorch_aug:\n",
    "    # Pytorch default & augmentation transform\n",
    "    transform_list = [augmentation.ImgAugTransform(with_aug=CONFIG['data']['imgaug_aug']),\n",
    "                      image_utils.CustomResize((CONFIG['data']['resize_img'],\n",
    "                                    CONFIG['data']['resize_img']),\n",
    "                                   _save_aspect_ratio\n",
    "                                   ),\n",
    "                      torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "                      torchvision.transforms.RandomHorizontalFlip(),\n",
    "                      torchvision.transforms.RandomRotation(20, resample=Image.BILINEAR),\n",
    "                      torchvision.transforms.ToTensor()\n",
    "                      ]\n",
    "else:\n",
    "    transform_list = [augmentation.ImgAugTransform(with_aug=CONFIG['data']['imgaug_aug']),\n",
    "                      image_utils.CustomResize((CONFIG['data']['resize_img'],\n",
    "                                    CONFIG['data']['resize_img']),\n",
    "                                   _save_aspect_ratio\n",
    "                                   ),\n",
    "                      torchvision.transforms.ToTensor()\n",
    "                      ]\n",
    "\n",
    "if _img_normalize:\n",
    "    # Parameters were taken from Pytorch example for Imagenet\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py#L197-L198\n",
    "    transform_list.append(torchvision.transforms.Normalize(mean=config.IMG_NORMALIZE_MEAN,\n",
    "                                                           std=config.IMG_NORMALIZE_STD)\n",
    "                          )\n",
    "    default_transforms_list.append(torchvision.transforms.Normalize(mean=config.IMG_NORMALIZE_MEAN,\n",
    "                                                                    std=config.IMG_NORMALIZE_STD)\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose(transform_list)\n",
    "val_trainsforms = torchvision.transforms.Compose(default_transforms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dictionaries for training, validation and testing\n",
    "TRAIN_DATASET_KWARGS = {'class_dict': CLASS_DICT,\n",
    "                        'dataset_rootdir': FULL_DATASET_DIR,\n",
    "                        'val_size': config.TESTVAL_SIZE,\n",
    "                        'test_size': config.TEST_SIZE_FROM_TESTVAL,   # Доля от val_size\n",
    "                        'seed': config.SEED,\n",
    "                        'torch_transform': train_transforms,\n",
    "                        }\n",
    "\n",
    "TESTVAL_DATASET_KWARGS = {'class_dict': CLASS_DICT,\n",
    "                          'dataset_rootdir': FULL_DATASET_DIR,\n",
    "                          'val_size': config.TESTVAL_SIZE,\n",
    "                          'test_size': config.TEST_SIZE_FROM_TESTVAL,  # Доля от val_size\n",
    "                          'seed': config.SEED,\n",
    "                          'torch_transform': val_trainsforms,\n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Pytorch TRAIN dataset kwargs:===========\n",
      "class_dict: {'ants': 0, 'bees': 1}\n",
      "dataset_rootdir: /home/alexander/Documents/py_projects/bitbucket/rsf_insects_recognition/datasets/test_data\n",
      "val_size: 0.3\n",
      "test_size: 0.5\n",
      "seed: 42\n",
      "torch_transform: Compose(\n",
      "    <utils.augmentation.ImgAugTransform object at 0x7f84e8bbe790>\n",
      "    <utils.image_utils.CustomResize object at 0x7f84e8bbe990>\n",
      "    ColorJitter(brightness=None, contrast=None, saturation=[0.95, 1.05], hue=[-0.05, 0.05])\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomRotation(degrees=(-20, 20), resample=2, expand=False)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "\n",
      "Unique classes in /home/alexander/Documents/py_projects/bitbucket/rsf_insects_recognition/datasets/test_data:\n",
      "['bees', 'ants']\n",
      "Mapping class dictionary: {'ants': 0, 'bees': 1}\n",
      "Number of observations for TRAIN: 170\n",
      "\n",
      "TRAIN classes:  2\n",
      "0    86\n",
      "1    84\n",
      "Name: class, dtype: int64\n",
      "VAL classes:  2\n",
      "1    18\n",
      "0    18\n",
      "Name: class, dtype: int64\n",
      "TEST classes:  2\n",
      "1    19\n",
      "0    19\n",
      "Name: class, dtype: int64\n",
      "===========Pytorch VAL dataset kwargs:============\n",
      "class_dict: {'ants': 0, 'bees': 1}\n",
      "dataset_rootdir: /home/alexander/Documents/py_projects/bitbucket/rsf_insects_recognition/datasets/test_data\n",
      "val_size: 0.3\n",
      "test_size: 0.5\n",
      "seed: 42\n",
      "torch_transform: Compose(\n",
      "    <utils.augmentation.ImgAugTransform object at 0x7f84e8bbe750>\n",
      "    <utils.image_utils.CustomResize object at 0x7f84e8bbe7d0>\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "\n",
      "Unique classes in /home/alexander/Documents/py_projects/bitbucket/rsf_insects_recognition/datasets/test_data:\n",
      "['bees', 'ants']\n",
      "Mapping class dictionary: {'ants': 0, 'bees': 1}\n",
      "Number of observations for VAL: 36\n",
      "\n",
      "TRAIN classes:  2\n",
      "0    86\n",
      "1    84\n",
      "Name: class, dtype: int64\n",
      "VAL classes:  2\n",
      "1    18\n",
      "0    18\n",
      "Name: class, dtype: int64\n",
      "TEST classes:  2\n",
      "1    19\n",
      "0    19\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_dataset = PytorchDataset('train', TRAIN_DATASET_KWARGS)\n",
    "val_dataset = PytorchDataset('val', TESTVAL_DATASET_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What sampler for batching to choose\n",
    "if CONFIG['imbalanced_tools']['train_sampler']:\n",
    "\n",
    "    _train_shuffle = False\n",
    "    _train_sampler = nn_utils.ImbalancedDatasetSampler(dataset=train_dataset,\n",
    "                                                       class_dict=CLASS_DICT,\n",
    "                                                       random_state=config.SEED)\n",
    "else:\n",
    "    _train_shuffle = True\n",
    "    _train_sampler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_dataset,\n",
    "                               batch_size=CONFIG['model']['batch_size'],\n",
    "                               shuffle=_train_shuffle, \n",
    "                               sampler=_train_sampler,\n",
    "                               num_workers=CONFIG['data']['num_workers'])\n",
    "val_data_loader = DataLoader(val_dataset, \n",
    "                             batch_size=CONFIG['model']['batch_size'],\n",
    "                             shuffle=True, \n",
    "                             num_workers=CONFIG['data']['num_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers and their parameters\n",
    "# https://pytorch.org/docs/stable/optim.html\n",
    "OPTIM_KWARGS = {'optimizer': {'adadelta': {'lr': 1.0, 'rho': 0.9, 'eps': 1e-06, 'weight_decay': 0},\n",
    "\n",
    "                              'adagrad': {'lr': 0.01, 'lr_decay': 0, 'weight_decay': 0,\n",
    "                                          'initial_accumulator_value': 0, 'eps': 1e-10},\n",
    "\n",
    "                              'adam': {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08,\n",
    "                                       'weight_decay': 0, 'amsgrad': False},\n",
    "\n",
    "                              'adamw': {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08,\n",
    "\n",
    "                                        'weight_decay': 0.01, 'amsgrad': False},\n",
    "\n",
    "                              'adamax': {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08,\n",
    "                                         'weight_decay': 0},\n",
    "\n",
    "                              'rms_prop': {'lr': 0.01, 'alpha': 0.99, 'eps': 1e-08, 'weight_decay': 0,\n",
    "                                           'momentum': 0, 'centered': False}\n",
    "                              },\n",
    "\n",
    "                'lr_scheduler': {'mode': 'min', 'factor': 0.95, 'patience': 10, 'verbose': False,\n",
    "                                 'threshold': 0.0001, 'threshold_mode': 'rel', 'cooldown': 0, 'min_lr': 1e-9,\n",
    "                                 'eps': 1e-08}\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: mobilenet_v2\n"
     ]
    }
   ],
   "source": [
    "# Select and configure model to be trained\n",
    "# Number of classes\n",
    "n_classes = len(TRAIN_DATASET_KWARGS['class_dict'].keys())\n",
    "\n",
    "if 'mobilenet' in CONFIG['model']['model_name']:\n",
    "    nnet = mobilenet_selector.get_mobilenet(version=CONFIG['model']['model_name'],\n",
    "                                            class_number=n_classes,\n",
    "                                            pretrained=CONFIG['model']['pretrained'],\n",
    "                                            freeze_conv=CONFIG['model']['freeze_conv'])\n",
    "else:\n",
    "    nnet = resnet_selector.get_resnet(version=CONFIG['model']['model_name'],\n",
    "                                      class_number=n_classes,\n",
    "                                      pretrained=CONFIG['model']['pretrained'],\n",
    "                                      freeze_conv=CONFIG['model']['freeze_conv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to use weighted loss or not\n",
    "if CONFIG['imbalanced_tools']['weighted_loss']:\n",
    "    _label_to_count = train_dataset.df_metadata['class'].value_counts().to_dict()\n",
    "    _unnorm_weights = {k: 1 / v for k, v in _label_to_count.items()}\n",
    "    _normed_weights = {k: v / sum(_unnorm_weights.values()) for k, v in _unnorm_weights.items()}\n",
    "\n",
    "    _loss_weight = [v for k, v in sorted(_normed_weights.items(), key=lambda x: x[0])]\n",
    "    _loss_weight = torch.FloatTensor(_loss_weight).to(DEVICE)\n",
    "\n",
    "else:\n",
    "    _loss_weight = None\n",
    "\n",
    "# Set training keyword argumetns\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=_loss_weight)\n",
    "optimizer = get_optimizer(CONFIG['model']['optimizer'],\n",
    "                          nnet,\n",
    "                          OPTIM_KWARGS['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset img hashes to dataset hash. Universal for every machine.\n",
    "train_data_hash = hashlib.sha1(\n",
    "    '_'.join(sorted(train_dataset.df_metadata['sha1'].values.tolist())).encode()).hexdigest()\n",
    "\n",
    "training_kwargs = {'device': DEVICE,\n",
    "\n",
    "                   'criterion': criterion,\n",
    "                   'optimizer': optimizer,\n",
    "                   'lr_scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                                              **OPTIM_KWARGS['lr_scheduler']),\n",
    "\n",
    "                   'data_loaders': {'train_loader': train_data_loader,\n",
    "                                    'val_loader': val_data_loader},\n",
    "                   'total_epochs': CONFIG['model']['epochs'],\n",
    "                   'batch_size': CONFIG['model']['batch_size'],\n",
    "                   'target_names': list(TRAIN_DATASET_KWARGS['class_dict'].keys()),\n",
    "\n",
    "                   'model_name': f\"\"\"{CONFIG['model']['model_name']}_{train_data_hash}\"\"\",\n",
    "                   'class_dict': CLASS_DICT,\n",
    "                   'save_path': os.path.join(os.getcwd(), 'weights'),\n",
    "                   'general_config': CONFIG\n",
    "                   }\n",
    "\n",
    "weights_folder = os.path.join(os.getcwd(), 'weights',\n",
    "                                  f\"\"\"pytorch_{CONFIG['model']['model_name']}_{train_data_hash}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neptune logger is OFF.\n"
     ]
    }
   ],
   "source": [
    "if config.USE_NEPTUNE:\n",
    "    print('Neptune logger is ON.')\n",
    "    # Сбор параметров для логгирования\n",
    "    TOTAL_PARAMS = {'config': CONFIG,\n",
    "                    'training_kwargs': training_kwargs,\n",
    "                    'train_dataset_kwargs': TRAIN_DATASET_KWARGS,\n",
    "                    'testval_dataset_kwargs': TESTVAL_DATASET_KWARGS,\n",
    "                    'weights_folder': weights_folder,\n",
    "                    'training_data_sha1': train_data_hash,\n",
    "                    }\n",
    "    neptune_kwargs = {'params': nested_to_record(TOTAL_PARAMS, sep='_'),\n",
    "                      'artifact_path': os.path.join(os.getcwd().replace('src', 'log_artifacts'), 'artifacts'),\n",
    "                      'image_path': os.path.join(os.getcwd().replace('src', 'log_artifacts'), 'images'),\n",
    "                      'tag_list': NEPTUNE_EXPERIMENT_TAG_LIST,\n",
    "                      'training_data_sha1': train_data_hash\n",
    "                      }\n",
    "    neptune_class = neptune_logger.NeptuneLogger(neptune_kwargs)\n",
    "else:\n",
    "    print('Neptune logger is OFF.')\n",
    "    neptune_class = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.66it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: inf -> 0.48677828907966614. Model was saved.\n",
      "[2.276771 sec.][Epoch 1] train_loss: 6.610351487994194, val_loss: 0.48677828907966614, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       1.00      0.83      0.91        18\n",
      "        bees       0.86      1.00      0.92        18\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.93      0.92      0.92        36\n",
      "weighted avg       0.93      0.92      0.92        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.22it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.270029 sec.][Epoch 2] train_loss: 4.160225257277489, val_loss: 0.6025669574737549, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.94      0.94      0.94        18\n",
      "        bees       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.94      0.94        36\n",
      "weighted avg       0.94      0.94      0.94        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.59it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.06it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.709707 sec.][Epoch 3] train_loss: 3.536779396235943, val_loss: 0.5929201245307922, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.93      0.78      0.85        18\n",
      "        bees       0.81      0.94      0.87        18\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.87      0.86      0.86        36\n",
      "weighted avg       0.87      0.86      0.86        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  5.03it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.80it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.508828 sec.][Epoch 4] train_loss: 3.308390859514475, val_loss: 1.2561622858047485, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.88      0.78      0.82        18\n",
      "        bees       0.80      0.89      0.84        18\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.84      0.83      0.83        36\n",
      "weighted avg       0.84      0.83      0.83        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  5.24it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.79it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.419902 sec.][Epoch 5] train_loss: 3.0779288709163666, val_loss: 2.321338653564453, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.93      0.78      0.85        18\n",
      "        bees       0.81      0.94      0.87        18\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.87      0.86      0.86        36\n",
      "weighted avg       0.87      0.86      0.86        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.77it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.06it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.22081 sec.][Epoch 6] train_loss: 2.3602486550807953, val_loss: 1.289846420288086, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.93      0.72      0.81        18\n",
      "        bees       0.77      0.94      0.85        18\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.85      0.83      0.83        36\n",
      "weighted avg       0.85      0.83      0.83        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.50it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.74it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.322329 sec.][Epoch 7] train_loss: 1.5529964994639158, val_loss: 0.6721146106719971, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       1.00      0.78      0.88        18\n",
      "        bees       0.82      1.00      0.90        18\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.91      0.89      0.89        36\n",
      "weighted avg       0.91      0.89      0.89        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.09it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.300741 sec.][Epoch 8] train_loss: 3.0569884292781353, val_loss: 0.8855840563774109, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.93      0.78      0.85        18\n",
      "        bees       0.81      0.94      0.87        18\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.87      0.86      0.86        36\n",
      "weighted avg       0.87      0.86      0.86        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.92it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.185996 sec.][Epoch 9] train_loss: 2.208288636058569, val_loss: 1.5977210998535156, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.89      0.89      0.89        18\n",
      "        bees       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.89      0.89      0.89        36\n",
      "weighted avg       0.89      0.89      0.89        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.14it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.154213 sec.][Epoch 10] train_loss: 2.0382276698946953, val_loss: 0.9035669565200806, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.93      0.78      0.85        18\n",
      "        bees       0.81      0.94      0.87        18\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.87      0.86      0.86        36\n",
      "weighted avg       0.87      0.86      0.86        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  5.41it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.87it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.353556 sec.][Epoch 11] train_loss: 1.3232023641467094, val_loss: 0.6963770985603333, learning_rate: 0.001.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.93      0.78      0.85        18\n",
      "        bees       0.81      0.94      0.87        18\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.87      0.86      0.86        36\n",
      "weighted avg       0.87      0.86      0.86        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.27it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.939624 sec.][Epoch 12] train_loss: 2.660275097936392, val_loss: 1.0027539730072021, learning_rate: 0.00095.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.93      0.78      0.85        18\n",
      "        bees       0.81      0.94      0.87        18\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.87      0.86      0.86        36\n",
      "weighted avg       0.87      0.86      0.86        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.64it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.66it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.275374 sec.][Epoch 13] train_loss: 2.6412623301148415, val_loss: 0.749087393283844, learning_rate: 0.00095.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ants       0.94      0.83      0.88        18\n",
      "        bees       0.85      0.94      0.89        18\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.89      0.89      0.89        36\n",
      "weighted avg       0.89      0.89      0.89        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 6/11 [00:02<00:01,  2.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-67e9fa55d3f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneptune_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneptune_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/py_projects/bitbucket/rsf_insects_recognition/src/utils/model_training_utils.py\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(net, training_kwargs, verbose, display_step, neptune_class)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m                                \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                      \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                     \u001b[0;31m# Make gradient step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                          \u001b[0;31m# Update total epoch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsfin/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsfin/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model_train(nnet, training_kwargs, neptune_class=neptune_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
